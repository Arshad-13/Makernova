{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix numpy compatibility and install TensorFlow 2.20 with dependencies\n",
    "print(\"🔧 Fixing numpy compatibility issues...\")\n",
    "\n",
    "# First, uninstall problematic packages\n",
    "!pip uninstall -y numpy opencv-python tensorflow\n",
    "\n",
    "# Install numpy first with specific version for TensorFlow 2.20\n",
    "!pip install numpy==1.26.4\n",
    "\n",
    "# Install TensorFlow 2.20 (it will use compatible numpy)\n",
    "!pip install tensorflow==2.20.0\n",
    "\n",
    "# Install other dependencies with compatible versions\n",
    "!pip install opencv-python==4.10.0.84\n",
    "!pip install pillow==10.4.0\n",
    "!pip install matplotlib==3.8.4\n",
    "\n",
    "print(\"🔄 Restarting Python kernel is recommended after installation...\")\n",
    "print(\"📋 Please restart the kernel and then run the verification cell below.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0423cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification Cell - Run this AFTER restarting the kernel\n",
    "print(\"🔍 Verifying installations...\")\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"✅ NumPy {np.__version__} - OK\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ NumPy error: {e}\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"✅ TensorFlow {tf.__version__} - OK\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ TensorFlow error: {e}\")\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    print(f\"✅ OpenCV {cv2.__version__} - OK\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ OpenCV error: {e}\")\n",
    "\n",
    "try:\n",
    "    import PIL\n",
    "    print(f\"✅ PIL {PIL.__version__} - OK\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ PIL error: {e}\")\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "    print(f\"✅ Matplotlib {matplotlib.__version__} - OK\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Matplotlib error: {e}\")\n",
    "\n",
    "print(\"\\n🎯 If all packages show ✅, you're ready to proceed!\")\n",
    "print(\"📝 If any show ❌, please run the installation cell again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import with error handling and modern TensorFlow APIs\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "    # Use tf.keras.utils.load_img instead of deprecated preprocessing.image\n",
    "    from tensorflow.keras.utils import load_img, img_to_array\n",
    "    import numpy as np\n",
    "    print(f\"✅ TensorFlow {tf.__version__} loaded successfully\")\n",
    "    print(\"✅ Using modern tf.keras APIs\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "    print(\"Please run the compatibility fix cell above and restart the kernel\")\n",
    "    raise\n",
    "\n",
    "# Load model with error handling\n",
    "try:\n",
    "    model = tf.keras.models.load_model('saved_models/waste_classifier_balanced.keras')\n",
    "    print(\"✅ Model loaded successfully\")\n",
    "    print(f\"Model input shape: {model.input_shape}\")\n",
    "    print(f\"Model output shape: {model.output_shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Model loading error: {e}\")\n",
    "    print(\"Please ensure the model file exists and TensorFlow is properly installed\")\n",
    "    raise\n",
    "\n",
    "def predict_waste(img_path):\n",
    "    \"\"\"Predict waste type from image path using modern tf.keras APIs\"\"\"\n",
    "    try:\n",
    "        # Use modern tf.keras.utils functions\n",
    "        img = load_img(img_path, target_size=(224, 224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        \n",
    "        prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "        \n",
    "        if prediction > 0.5:\n",
    "            return f\"Non-biodegradable (confidence: {prediction:.2%})\"\n",
    "        else:\n",
    "            return f\"Biodegradable (confidence: {1-prediction:.2%})\"\n",
    "    except Exception as e:\n",
    "        return f\"Error predicting: {e}\"\n",
    "\n",
    "print(\"✅ Prediction function ready!\")\n",
    "print(\"Example usage:\")\n",
    "print(\"result = predict_waste('dataset/mt/t1.webp')\")\n",
    "print(\"print(result)\")\n",
    "\n",
    "# Test if we can make a sample prediction (uncomment to test)\n",
    "# try:\n",
    "#     result = predict_waste('dataset/mt/t1.webp')\n",
    "#     print(f\"Test result: {result}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3334df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Waste Classification using Laptop Camera (Updated with modern APIs)\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "class RealTimeWasteClassifier:\n",
    "    def __init__(self, model_path):\n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"✅ Real-time classifier model loaded: {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load real-time model: {e}\")\n",
    "            raise\n",
    "        \n",
    "        self.cap = None\n",
    "        self.classification_interval = 1.0  # Classify every 1 second\n",
    "        self.last_classification_time = 0\n",
    "        self.current_prediction = \"Ready to classify...\"\n",
    "        self.confidence = 0.0\n",
    "        \n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Preprocess camera frame for model prediction using modern APIs\"\"\"\n",
    "        try:\n",
    "            # Convert BGR to RGB\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Convert to PIL Image and resize\n",
    "            pil_image = Image.fromarray(rgb_frame)\n",
    "            pil_image = pil_image.resize((224, 224))\n",
    "            \n",
    "            # Convert to array and preprocess\n",
    "            img_array = np.array(pil_image, dtype=np.float32)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            \n",
    "            return img_array\n",
    "        except Exception as e:\n",
    "            print(f\"Frame preprocessing error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def predict_frame(self, frame):\n",
    "        \"\"\"Predict waste type from camera frame\"\"\"\n",
    "        try:\n",
    "            processed_frame = self.preprocess_frame(frame)\n",
    "            if processed_frame is None:\n",
    "                return \"Error\", 0.0, (255, 255, 255)\n",
    "                \n",
    "            prediction = self.model.predict(processed_frame, verbose=0)[0][0]\n",
    "            \n",
    "            if prediction > 0.5:\n",
    "                waste_type = \"Non-biodegradable\"\n",
    "                confidence = prediction\n",
    "                color = (0, 0, 255)  # Red for non-biodegradable\n",
    "            else:\n",
    "                waste_type = \"Biodegradable\"\n",
    "                confidence = 1 - prediction\n",
    "                color = (0, 255, 0)  # Green for biodegradable\n",
    "            \n",
    "            return waste_type, confidence, color\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "            return \"Error\", 0.0, (255, 255, 255)\n",
    "    \n",
    "    def add_text_overlay(self, frame, waste_type, confidence, color):\n",
    "        \"\"\"Add prediction overlay to frame\"\"\"\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (10, 10), (500, 100), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "        \n",
    "        # Add main prediction text\n",
    "        cv2.putText(frame, f\"Prediction: {waste_type}\", \n",
    "                   (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "        \n",
    "        # Add confidence text\n",
    "        cv2.putText(frame, f\"Confidence: {confidence:.1%}\", \n",
    "                   (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # Add instructions\n",
    "        cv2.putText(frame, \"Press 'q' to quit, 's' to save frame\", \n",
    "                   (10, frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def start_camera(self):\n",
    "        \"\"\"Start real-time camera classification\"\"\"\n",
    "        print(\"Starting camera... Press 'q' to quit, 's' to save current frame\")\n",
    "        \n",
    "        # Initialize camera\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not self.cap.isOpened():\n",
    "            print(\"Error: Could not open camera\")\n",
    "            return\n",
    "        \n",
    "        # Set camera properties\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        \n",
    "        frame_count = 0\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Error: Could not read frame\")\n",
    "                    break\n",
    "                \n",
    "                # Flip frame horizontally for mirror effect\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                \n",
    "                # Classify frame periodically\n",
    "                current_time = time.time()\n",
    "                if current_time - self.last_classification_time >= self.classification_interval:\n",
    "                    waste_type, confidence, color = self.predict_frame(frame)\n",
    "                    self.current_prediction = waste_type\n",
    "                    self.confidence = confidence\n",
    "                    self.color = color\n",
    "                    self.last_classification_time = current_time\n",
    "                \n",
    "                # Add overlay with current prediction\n",
    "                if hasattr(self, 'color'):\n",
    "                    frame = self.add_text_overlay(frame, self.current_prediction, \n",
    "                                                self.confidence, self.color)\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Real-time Waste Classification', frame)\n",
    "                \n",
    "                # Handle key presses\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('s'):\n",
    "                    # Save current frame\n",
    "                    filename = f\"classified_frame_{int(time.time())}.jpg\"\n",
    "                    cv2.imwrite(filename, frame)\n",
    "                    print(f\"Frame saved as {filename}\")\n",
    "                \n",
    "                frame_count += 1\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nStopping camera...\")\n",
    "        \n",
    "        finally:\n",
    "            self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Camera stopped.\")\n",
    "\n",
    "# Initialize the real-time classifier\n",
    "classifier = RealTimeWasteClassifier('saved_models/waste_classifier_balanced.keras')\n",
    "\n",
    "print(\"Real-time Waste Classifier Ready!\")\n",
    "print(\"Instructions:\")\n",
    "print(\"- Run classifier.start_camera() to begin\")\n",
    "print(\"- Point camera at waste items\")\n",
    "print(\"- Press 'q' to quit\")\n",
    "print(\"- Press 's' to save current frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce0db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Real-time Classification\n",
    "# Run this cell to start the camera classification\n",
    "\n",
    "# Start the camera (uncomment the line below to run)\n",
    "# classifier.start_camera()\n",
    "\n",
    "# Alternative: Test with a specific region of interest\n",
    "def start_camera_with_roi():\n",
    "    \"\"\"Start camera with a region of interest box for better classification\"\"\"\n",
    "    print(\"Starting camera with ROI... Press 'q' to quit\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera\")\n",
    "        return\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    # ROI coordinates (center square)\n",
    "    roi_size = 200\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame = cv2.flip(frame, 1)\n",
    "            h, w = frame.shape[:2]\n",
    "            \n",
    "            # Calculate ROI coordinates\n",
    "            roi_x1 = w//2 - roi_size//2\n",
    "            roi_y1 = h//2 - roi_size//2\n",
    "            roi_x2 = roi_x1 + roi_size\n",
    "            roi_y2 = roi_y1 + roi_size\n",
    "            \n",
    "            # Extract ROI\n",
    "            roi = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "            \n",
    "            # Classify ROI\n",
    "            if roi.size > 0:\n",
    "                try:\n",
    "                    # Convert ROI to RGB\n",
    "                    rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "                    pil_image = Image.fromarray(rgb_roi)\n",
    "                    pil_image = pil_image.resize((224, 224))\n",
    "                    \n",
    "                    img_array = np.array(pil_image)\n",
    "                    img_array = np.expand_dims(img_array, axis=0)\n",
    "                    img_array = preprocess_input(img_array)\n",
    "                    \n",
    "                    prediction = classifier.model.predict(img_array, verbose=0)[0][0]\n",
    "                    \n",
    "                    if prediction > 0.5:\n",
    "                        waste_type = \"Non-biodegradable\"\n",
    "                        confidence = prediction\n",
    "                        color = (0, 0, 255)  # Red\n",
    "                    else:\n",
    "                        waste_type = \"Biodegradable\"\n",
    "                        confidence = 1 - prediction\n",
    "                        color = (0, 255, 0)  # Green\n",
    "                    \n",
    "                    # Draw ROI box\n",
    "                    cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), color, 3)\n",
    "                    \n",
    "                    # Add text\n",
    "                    cv2.putText(frame, f\"{waste_type} ({confidence:.1%})\", \n",
    "                               (roi_x1, roi_y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Draw white ROI box on error\n",
    "                    cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 255, 255), 2)\n",
    "                    cv2.putText(frame, \"Processing...\", \n",
    "                               (roi_x1, roi_y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Instructions\n",
    "            cv2.putText(frame, \"Place waste item in the box\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, \"Press 'q' to quit\", \n",
    "                       (10, frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            \n",
    "            cv2.imshow('Waste Classification - ROI Mode', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopping camera...\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Camera stopped.\")\n",
    "\n",
    "print(\"Camera functions ready!\")\n",
    "print(\"\\nOptions to start:\")\n",
    "print(\"1. classifier.start_camera()          # Full screen classification\")\n",
    "print(\"2. start_camera_with_roi()            # Region of interest mode\")\n",
    "print(\"\\nRecommended: Use option 2 for better accuracy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4038e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_camera_with_roi()\n",
    "classifier.start_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0998060b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c3769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
